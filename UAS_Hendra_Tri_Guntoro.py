# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CL6gG0NlKvloQbsGeVkUKlOXrCNz0BFt
"""

!pip install mlxtend

import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.utils import to_categorical
from sklearn.model_selection import LeaveOneOut
from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score
import matplotlib.pyplot as plt

# Load data
train_data = pd.read_csv('/content/emnist-bymerge-train.csv', header=None)

# Preprocess data
X_train = train_data.iloc[:, 1:].values.reshape(-1, 28, 28, 1).astype('float32') / 255.0  # Normalize pixel values
y_train = to_categorical(train_data.iloc[:, 0].values.astype('int'))  # One-hot encode labels

# Limit the dataset size for quick iteration
max_samples = 200  # Reduce dataset size further
if len(X_train) > max_samples:
    X_train = X_train[:max_samples]
    y_train = y_train[:max_samples]

# Define CNN model (simplified for faster training)
model = Sequential([
    Conv2D(16, (3, 3), activation='relu', input_shape=(28, 28, 1)),
    MaxPooling2D((2, 2)),
    Flatten(),
    Dense(32, activation='relu'),  # Reduce dense layer size
    Dropout(0.3),  # Lower dropout rate
    Dense(y_train.shape[1], activation='softmax')
])

model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])

# LOOCV Setup
loo = LeaveOneOut()
n_classes = y_train.shape[1]
y_true = []
y_pred = []

# Train and Evaluate using LOOCV
for train_index, val_index in loo.split(X_train):
    X_train_fold, X_val_fold = X_train[train_index], X_train[val_index]
    y_train_fold, y_val_fold = y_train[train_index], y_train[val_index]

    # Train model with fewer epochs and increased batch size
    model.fit(X_train_fold, y_train_fold, epochs=3, batch_size=64, verbose=0)

    # Predict
    predictions = model.predict(X_val_fold, verbose=0)
    y_true.append(np.argmax(y_val_fold, axis=1)[0])
    y_pred.append(np.argmax(predictions, axis=1)[0])

# Calculate metrics
loo_confusion_matrix = confusion_matrix(y_true, y_pred)
loo_accuracy = accuracy_score(y_true, y_pred)
loo_precision = precision_score(y_true, y_pred, average='weighted')
loo_recall = recall_score(y_true, y_pred, average='weighted')
loo_f1 = f1_score(y_true, y_pred, average='weighted')

print("\nLOOCV Results:")
print("Confusion Matrix:")
print(loo_confusion_matrix)
print("Accuracy:", loo_accuracy)
print("Precision:", loo_precision)
print("Recall:", loo_recall)
print("F1 Score:", loo_f1)

# Plot confusion matrix
def plot_confusion_mat(cm):
    plt.figure(figsize=(8, 8))
    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)
    plt.title('Confusion Matrix')
    plt.colorbar()
    tick_marks = np.arange(cm.shape[0])
    plt.xticks(tick_marks, tick_marks, rotation=45)
    plt.yticks(tick_marks, tick_marks)

    # Add labels in each cell
    fmt = 'd'
    thresh = cm.max() / 2.
    for i in range(cm.shape[0]):
        for j in range(cm.shape[1]):
            plt.text(j, i, format(cm[i, j], fmt),
                     horizontalalignment="center",
                     color="white" if cm[i, j] > thresh else "black")

    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.show()

plot_confusion_mat(loo_confusion_matrix)

from getpass import getpass
import os

os.environ['GITHUB_USERNAME'] = getpass('GITHUB username: ')
os.environ['GITHUB_TOKEN'] = getpass('GITHUB token: ')